Project Overview

This project analyzes the performance of various AI models across different tasks using SQL, Google Sheets, and Tableau. The goal is to compare accuracy and response time across AI models and gain insights into which models perform best for different AI tasks.


Tools & Technologies Used
SQL – Data extraction, aggregation, and filtering
Google Sheets – Data cleaning and review
Tableau – Data visualization and insights


AI Model Performance Visualizations: The Story Behind the Data

1. Scatter Plot: Accuracy vs. Response Time
This chart highlights the trade-off between accuracy and speed for each AI model.

 Key Takeaways:
GPT-4 is the most accurate (92%), but has a slower response time (~900ms).
Claude 3 is the fastest (response time ~850ms), but also the least accurate (88%).
Gemini 1.5 offers the best balance, with high accuracy (90%) and the fastest response time (750ms).

Insight: Higher performing models tend to be slower speed vs. intelligence trade off.


2. Bar Chart: AI Task Performance – Average Accuracy Comparison
This chart compares how accurate models are for different types of AI tasks.

Key Takeaways:
Code Generation had the highest overall accuracy (93%)
Natural Language Processing (NLP) followed with 90%
Image Recognition had the lowest average accuracy (85%)

Insight: AI models handle code and language better than visual data.


3. Line Chart: AI Model Performance Trends
This line chart shows how each AI model performs across different tasks.

Key Takeaways:
All models struggled with Image Recognition
GPT-4 outperformed other models across all tasks
Claude 3 consistently had the lowest accuracy

Insight: GPT-4 is the most reliable model, especially for Code Generation.


4. Heatmap: Response Time by Task Type
This heatmap shows how quickly each model completes each type of task.

Key Takeaways:
Gemini 1.5 is the fastest model across all tasks
Claude 3 is the slowest, especially for Image Recognition (1,300ms)
NLP is the fastest task for every model

Efficiency varies not just by model, but also by task. Visual tasks take the longest to process.
